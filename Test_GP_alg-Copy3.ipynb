{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa1117eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy.spatial.distance\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dff3571",
   "metadata": {},
   "outputs": [],
   "source": [
    "GT = np.genfromtxt('ds0_Groundtruth.dat', skip_header = 3, skip_footer = 0, names = True, dtype = None, delimiter = ' ' , usecols = [0, 3, 5, 7])\n",
    "Odom = np.genfromtxt('ds0_Odometry.dat', skip_header = 3, skip_footer = 0, names = True, dtype = None, delimiter = ' ' , usecols = [0,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8326c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = GT[0][0]\n",
    "for i in range(len(GT)):\n",
    "    GT[i][0]-= start_time\n",
    "for i in range(len(Odom)):\n",
    "    Odom[i][0]-=start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72a5b82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 1\n",
    "k = 1\n",
    "align = []\n",
    "\n",
    "for i in range (len(GT)):\n",
    "    match = 0\n",
    "    while (match == 0 and j < len(GT) and k < len(Odom)-1):\n",
    "        if (GT[j][0] - Odom[k][0] > 0 and GT[j][0] - Odom[k+1][0]<= 0):\n",
    "            align.append((GT[j], Odom[k]))\n",
    "            j+=1\n",
    "            match = 1\n",
    "        else:\n",
    "            k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "742bae9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_in = []\n",
    "train_out = []\n",
    "\n",
    "test_in = []\n",
    "test_out = []\n",
    "\n",
    "val_in = []\n",
    "val_out = []\n",
    "\n",
    "ind = np.linspace(0, len(align), 10000)\n",
    "ind_count = 0\n",
    "\n",
    "for i in range(len(align) - 2):\n",
    "    \n",
    "    dt_in = align[i+1][0][0] - align[i][0][0]\n",
    "    \n",
    "    x_in = align[i+1][0][1] - align[i][0][1]\n",
    "    y_in = align[i+1][0][2] - align[i][0][2]\n",
    "    theta_in = align[i+1][0][3] - align[i][0][3]\n",
    "    \n",
    "    v_in = align[i+1][1][1] - align[i][1][1]\n",
    "    w_in = align[i+1][1][2] - align[i][1][2]\n",
    "\n",
    "    dt_out = align[i+2][0][0] - align[i+1][0][0] # (t+1) - (t)\n",
    "    \n",
    "    x_out = align[i+2][0][1] - align[i+1][0][1]\n",
    "    y_out = align[i+2][0][2] - align[i+1][0][2]\n",
    "    theta_out = align[i+2][0][3] - align[i+1][0][3]\n",
    "    \n",
    "    if (i == int(ind[ind_count]) and ind_count%2 ==0):\n",
    "        test_in.append([x_in/dt_in, y_in/dt_in, theta_in/dt_in, v_in/dt_out, w_in/dt_out])\n",
    "        test_out.append([x_out/dt_out, y_out/dt_out, theta_out/dt_out])\n",
    "        ind_count+=1\n",
    "    elif (i == int(ind[ind_count]) and ind_count%2 ==1):\n",
    "        val_in.append([x_in/dt_in, y_in/dt_in, theta_in/dt_in, v_in/dt_out, w_in/dt_out])\n",
    "        val_out.append([x_out/dt_out, y_out/dt_out, theta_out/dt_out])\n",
    "        ind_count+=1\n",
    "    else:\n",
    "        train_in.append([x_in/dt_in, y_in/dt_in, theta_in/dt_in, v_in/dt_out, w_in/dt_out])\n",
    "        train_out.append([x_out/dt_out, y_out/dt_out, theta_out/dt_out])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f07f049",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_in2 = []\n",
    "train_out2 = []\n",
    "\n",
    "test_in2 = []\n",
    "test_out2 = []\n",
    "\n",
    "val_in2 = []\n",
    "val_out2 = []\n",
    "\n",
    "ind = np.linspace(0, len(align), 10000)\n",
    "ind_count = 0\n",
    "\n",
    "for i in range(len(align) - 2):\n",
    "    \n",
    "    dt_in = align[i+1][0][0] - align[i][0][0]\n",
    "    \n",
    "    x_in = align[i+1][0][1] - align[i][0][1]\n",
    "    y_in = align[i+1][0][2] - align[i][0][2]\n",
    "    theta_in = align[i+1][0][3] - align[i][0][3]\n",
    "    \n",
    "    v = np.sqrt(((x_in/dt_in)**2)+((y_in/dt_in)**2))\n",
    "    w = theta_in/dt_in\n",
    "    \n",
    "    v_in = align[i+1][1][1] - align[i][1][1]\n",
    "    w_in = align[i+1][1][2] - align[i][1][2]\n",
    "    \n",
    "    del_v = np.abs(v - v_in)\n",
    "    del_w = np.abs(w - w_in)\n",
    "\n",
    "    dt_out = align[i+2][0][0] - align[i+1][0][0] # (t+1) - (t)\n",
    "    \n",
    "    x_out = align[i+2][0][1] - align[i+1][0][1]\n",
    "    y_out = align[i+2][0][2] - align[i+1][0][2]\n",
    "    theta_out = align[i+2][0][3] - align[i+1][0][3]\n",
    "    \n",
    "    if (i == int(ind[ind_count]) and ind_count%2 ==0):\n",
    "        test_in2.append([del_v, del_w, dt_out])\n",
    "        test_out2.append([x_out, y_out, theta_out])\n",
    "        ind_count+=1\n",
    "    elif (i == int(ind[ind_count]) and ind_count%2 ==1):\n",
    "        val_in2.append([del_v, del_w, dt_out])\n",
    "        val_out2.append([x_out, y_out, theta_out])\n",
    "        ind_count+=1\n",
    "    else:\n",
    "        train_in2.append([del_v, del_w, dt_out])\n",
    "        train_out2.append([x_out, y_out, theta_out])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77319c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RBF_1d(X1, X2, l, var):\n",
    "    '''\n",
    "        l = lengthscale\n",
    "        var = variance (sigma^2)\n",
    "        \n",
    "        scipy.spatial.distance.cdist(XA, XB, metric='euclidean', *, out=None, **kwargs)\n",
    "        Compute distance between each pair of the two collections of inputs.\n",
    "        https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cdist.html\n",
    "        \n",
    "        Kxx = | k(x1,x1)   k(x1,x2)   ....   k(x1,xn) |\n",
    "              |                                       |\n",
    "              | k(xn,x1)   k(xn,x2)   ....   k(xn,xn) |\n",
    "    '''\n",
    "    K = np.zeros((len(X1), len(X2)))\n",
    "    for i in range(len(X1)):\n",
    "        for j in range(len(X2)):\n",
    "            d = np.abs(X1[i] - X2[j])\n",
    "            K[i][j] = var*np.exp(-(d**2)/(2*(l**2)))\n",
    "            #K[j][i] = var*np.exp(-(d**2)/(2*(l**2)))\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efb7d3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GP_1d(x_in, y_out, x_test, l, var):\n",
    "    '''\n",
    "        x_in = 1D array of training input\n",
    "        y_out = 1D array of training output\n",
    "        x_test = single point of test input\n",
    "    '''\n",
    "    # compute kernel, covar of training input\n",
    "    Kxx = RBF_1d(x_in, x_in, l, var)\n",
    "\n",
    "    L = np.linalg.cholesky(Kxx + 1e-5*np.eye(x_in.shape[0])) # add noise\n",
    "    # https://numpy.org/doc/stable/reference/generated/numpy.linalg.cholesky.html\n",
    "    \n",
    "    alpha = scipy.linalg.solve_triangular(L.T, scipy.linalg.solve_triangular(L, y_out, lower=True)) # solve(a, b) --> ax = b --> x = a\\b = a^-1b\n",
    "    # https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.solve_triangular.html\n",
    "    # https://numpy.org/doc/stable/reference/generated/numpy.linalg.solve.html\n",
    "    \n",
    "    # compute covar\n",
    "    Kxxt = RBF_1d(x_in, x_test, l, var)\n",
    "\n",
    "    # compute covar of test data\n",
    "    Kxtxt = RBF_1d(x_test, x_test, l, var)\n",
    "    \n",
    "    # compute posterior mean\n",
    "    mu_post = np.matmul(Kxxt.T, alpha)    \n",
    "    \n",
    "    #compute poserior covar\n",
    "    v = scipy.linalg.solve_triangular(L.T, scipy.linalg.solve_triangular(L, Kxxt, lower=True))\n",
    "    sigma_post = Kxtxt - np.matmul(Kxxt.T, v)\n",
    "    \n",
    "    #sigma = Kxtxt - np.dot(Kxxt, np.linalg.inv(Kxx).dot(Kxxt))\n",
    "    # https://blog.dominodatalab.com/fitting-gaussian-process-models-python\n",
    "    \n",
    "    #mu_post = np.dot((scipy.linalg.solve(Kxx, Kxxt, assume_a='pos').T), y_out)\n",
    "    #mu_post = (scipy.linalg.solve(Kxx, Kxxt, assume_a='pos').T) * y_out\n",
    "    #sigma_post = Kxtxt - np.dot((scipy.linalg.solve(Kxx, Kxxt, assume_a='pos').T), Kxxt) \n",
    "    # https://peterroelants.github.io/posts/gaussian-process-tutorial/\n",
    "    \n",
    "    return mu_post, sigma_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "186551db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RBF_nd(X1, X2, l, var):\n",
    "    '''\n",
    "        l = lengthscale\n",
    "        var = variance (sigma^2)\n",
    "        \n",
    "        scipy.spatial.distance.cdist(XA, XB, metric='euclidean', *, out=None, **kwargs)\n",
    "        Compute distance between each pair of the two collections of inputs.\n",
    "        https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cdist.html\n",
    "        \n",
    "        Kxx = | k(x1,x1)   k(x1,x2)   ....   k(x1,xn) |\n",
    "              |                                       |\n",
    "              | k(xn,x1)   k(xn,x2)   ....   k(xn,xn) |\n",
    "    '''\n",
    "    d = scipy.spatial.distance.cdist(X1, X2, 'cityblock')\n",
    "    K = var * np.exp(-(d**2)/(2*(l**2)))\n",
    "    return K\n",
    "    \n",
    "def GP(x_in, y_out, x_test, l, var, noise, prior_mean):\n",
    "    #prior_mean = 0\n",
    "    #noise = 1e-5\n",
    "    \n",
    "    Kxx = RBF_nd(x_in, x_in, l, var)\n",
    "\n",
    "    L = np.linalg.cholesky(Kxx + noise*np.eye(x_in.shape[0])) # add noise\n",
    "\n",
    "    alpha = scipy.linalg.solve_triangular(L.T, scipy.linalg.solve_triangular(L, y_out, lower=True)) # solve(a, b) --> ax = b --> x = a\\b = a^-1b\n",
    "\n",
    "    Kxxt = RBF_nd(x_in, x_test, l, var)\n",
    "\n",
    "    Kxtxt = RBF_nd(x_test, x_test, l, var)\n",
    "\n",
    "    mu_post = np.matmul(Kxxt.T, alpha)\n",
    "\n",
    "    v = scipy.linalg.solve_triangular(L.T, scipy.linalg.solve_triangular(L, Kxxt, lower=True))\n",
    "    sigma_post = Kxtxt - np.matmul(Kxxt.T, v)\n",
    "    \n",
    "    return mu_post, sigma_post\n",
    " \n",
    "def log_like(x_in, y_out, x_test, l, var, noise):\n",
    "    Kxx = RBF_nd(x_in, x_in, l, var)\n",
    "    \n",
    "    L = np.linalg.cholesky(Kxx + noise*np.eye(x_in.shape[0])) # add noise\n",
    "\n",
    "    alpha = scipy.linalg.solve_triangular(L.T, scipy.linalg.solve_triangular(L, y_out, lower=True)) # solve(a, b) --> ax = b --> x = a\\b = a^-1b\n",
    "\n",
    "    #MLL = (-.5*train_out.T*np.inv(Kxx)*train_out) - (.5*np.log(Kxx)) - (n/2)*np.log(2*np.pi)\n",
    "    \n",
    "    #np.sum(np.log(np.abs(K_chol))) + np.sum(scipy.linalg.solve_triangular((y_out), K_chol)**2) - \n",
    "\n",
    "    temp = 0\n",
    "    n = len(x_in) #num training points\n",
    "    for i in range(len(L)):\n",
    "        temp+=np.log(L[i][i])\n",
    "    MLL = -.5*y_out.T*alpha - temp - (n/2)*np.log(2*np.pi)\n",
    "    return MLL\n",
    "\n",
    "def log_like_1d(x_in, y_out, x_test, l, var):\n",
    "    Kxx = RBF_1d(x_in, x_in, l, var)\n",
    "    \n",
    "    L = np.linalg.cholesky(Kxx + 1e-5*np.eye(x_in.shape[0])) # add noise\n",
    "\n",
    "    alpha = scipy.linalg.solve_triangular(L.T, scipy.linalg.solve_triangular(L, y_out, lower=True)) # solve(a, b) --> ax = b --> x = a\\b = a^-1b\n",
    "\n",
    "    #MLL = (-.5*train_out.T*np.inv(Kxx)*train_out) - (.5*np.log(Kxx)) - (n/2)*np.log(2*np.pi)\n",
    "    \n",
    "    #np.sum(np.log(np.abs(K_chol))) + np.sum(scipy.linalg.solve_triangular((y_out), K_chol)**2) - \n",
    "\n",
    "    temp = 0\n",
    "    n = len(x_in) #num training points\n",
    "    for i in range(len(L)):\n",
    "        temp+=np.log(L[i][i])\n",
    "    MLL = -.5*y_out.T*alpha - temp - (n/2)*np.log(2*np.pi)\n",
    "    return MLL\n",
    "    \n",
    "def least_squares(y_pred, y_true):\n",
    "    total = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        total+=((y_pred[i] - y_true[i])**2)\n",
    "    return total\n",
    "\n",
    "#def grad_descent():\n",
    "    \n",
    "def gradient_descent(loss_func, alpha_choice, max_its, params):\n",
    "    g_flat, unflatten, w = flatten_func(loss_func, params) # note here the output 'w' is also flattened\n",
    "\n",
    "    # compute the gradient function of our input function - note this is a function too\n",
    "    # that - when evaluated - returns both the gradient and function evaluations (remember\n",
    "    # as discussed in Chapter 3 we always ge the function evaluation 'for free' when we use\n",
    "    # an Automatic Differntiator to evaluate the gradient)\n",
    "    gradient = value_and_grad(g_flat)\n",
    "\n",
    "    # run the gradient descent loop\n",
    "    weight_history = []      # container for weight history\n",
    "    cost_history = []        # container for corresponding cost function history\n",
    "    alpha = 0\n",
    "    for k in range(1,max_its+1):\n",
    "        # check if diminishing steplength rule used\n",
    "        if alpha_choice == 'diminishing':\n",
    "            alpha = 1/float(k)\n",
    "        else:\n",
    "            alpha = alpha_choice\n",
    "        \n",
    "        # evaluate the gradient, store current (unflattened) weights and cost function value\n",
    "        cost_eval,grad_eval = gradient(w)\n",
    "        weight_history.append(unflatten(w))\n",
    "        cost_history.append(cost_eval)\n",
    "\n",
    "        # take gradient descent step\n",
    "        params = params - alpha*grad_eval\n",
    "            \n",
    "    # collect final weights\n",
    "    weight_history.append(unflatten(w))\n",
    "    # compute final cost function value via g itself (since we aren't computing \n",
    "    # the gradient at the final step we don't get the final cost function value \n",
    "    # via the Automatic Differentiatoor) \n",
    "    cost_history.append(g_flat(w))  \n",
    "    return weight_history[-1],cost_history[-1]\n",
    "\n",
    "#def optimize():\n",
    "        \n",
    "#def log_max():\n",
    "\n",
    "def MSE(mean_out, y_true):\n",
    "    total = 0\n",
    "    for i in range(len(mean_out)):\n",
    "        total+=((mean_out[i][0] - y_true[i])**2)\n",
    "    return total\n",
    "\n",
    "def neg_log_prob(mean_out, y_true, post_var):\n",
    "    noise = 1e-5*np.eye(post_var.shape[0])\n",
    "    pred_var = post_var + noise\n",
    "    #print((2*np.pi*pred_var))\n",
    "    return .5*np.log(2*np.pi*(np.abs(pred_var))) + ((y_true-mean_out)**2)/(2*pred_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436811be",
   "metadata": {},
   "source": [
    "https://blog.dominodatalab.com/fitting-gaussian-process-models-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a571ae59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13537656937377718\n",
      "228.8964549583484 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-09cca61dc119>:14: RuntimeWarning: covariance is not positive-semidefinite.\n",
      "  y_predict = np.random.multivariate_normal(mu.reshape(len(x_test)), sigma)\n"
     ]
    }
   ],
   "source": [
    "x_train = train_in2[0:1000]\n",
    "x_test = test_in2[0:100]\n",
    "y_train = np.zeros(1000)\n",
    "y_true = np.zeros(100)\n",
    "\n",
    "for i in range(1000):\n",
    "    y_train[i] = train_out2[i][0]\n",
    "    \n",
    "for i in range(100):\n",
    "    y_true[i] = test_out2[i][0]\n",
    "\n",
    "mu, sigma = GP(x_train, y_train, x_test, 100, .1, 1e-1, 0)\n",
    "\n",
    "y_predict = np.random.multivariate_normal(mu.reshape(len(x_test)), sigma)\n",
    "\n",
    "print(least_squares(y_predict, y_true))\n",
    "\n",
    "LL = log_like(x_train, y_train, x_test, 100, 0.1, 1e-1)\n",
    "print(LL[0], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e746c2e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-e85b00ee805e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Fit GPR model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mgpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Predict mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, DotProduct, RBF\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Random seeds\n",
    "np.random.seed(seed=0)  # Set seed for NumPy\n",
    "random_state = 0\n",
    "\n",
    "\n",
    "# Create kernel and define GPR\n",
    "kernel = RBF() + WhiteKernel()\n",
    "gpr = GaussianProcessRegressor(kernel=kernel, random_state=random_state)\n",
    "\n",
    "# Fit GPR model\n",
    "gpr.fit(x_train[0:1000], y_train[0:1000])\n",
    " \n",
    "# Predict mean\n",
    "y_hat, y_sigma = gpr.predict(x_test[0:100], return_std=True)\n",
    "\n",
    "\n",
    "#print(gpr.get_params)\n",
    "print(gpr.log_marginal_likelihood_value_)\n",
    "print(gpr.kernel_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef9df131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00019495051228896152\n",
      "2323.1935026559586\n"
     ]
    }
   ],
   "source": [
    "mu, sigma = GP(x_train[0:100], y_train[0:100], x_test[0:10], 21.6, .00001, 1e-1, 0)\n",
    "\n",
    "y_predict = np.random.multivariate_normal(mu.reshape(10,), sigma)\n",
    "\n",
    "print(least_squares(y_predict, y_true))\n",
    "\n",
    "LL = log_like(x_train, y_train, x_test, 21.6, 0.00001, 1e-1)\n",
    "print(LL[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b45e22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_in3 = []\n",
    "train_out3 = []\n",
    "\n",
    "test_in3 = []\n",
    "test_out3 = []\n",
    "\n",
    "val_in3 = []\n",
    "val_out3 = []\n",
    "\n",
    "ind = np.linspace(0, len(align), 10000)\n",
    "ind_count = 0\n",
    "index = 0\n",
    "\n",
    "for i in range(2000):\n",
    "    dt_in = 0\n",
    "    dt_out = 0\n",
    "    v_in = 0\n",
    "    w_in = 0\n",
    "    \n",
    "    x_in = align[index+25][0][1] - align[index][0][1]\n",
    "    y_in = align[index+25][0][2] - align[index][0][2]\n",
    "    theta_in = align[index+25][0][3] - align[index][0][3]\n",
    "    \n",
    "    for j in range(25):\n",
    "        dt_in += align[index+1][0][0] - align[index][0][0] #sum 25 timesteps\n",
    "        dt_out += align[index+2][0][0] - align[index+1][0][0] # (t+1) - (t)\n",
    "        \n",
    "        v_in += align[index+1][1][1] - align[index][1][1]\n",
    "        w_in += align[index+1][1][2] - align[index][1][2]\n",
    "\n",
    "        index+=1\n",
    "        \n",
    "    v_in = v_in/25 #average of 25 timesteps\n",
    "    w_in = w_in/25\n",
    "    \n",
    "    v = np.sqrt(((x_in/dt_in)**2)+((y_in/dt_in)**2))\n",
    "    w = theta_in/dt_in\n",
    "\n",
    "    del_v = np.abs(v - v_in)\n",
    "    del_w = np.abs(w - w_in)\n",
    "\n",
    "    x_out = align[index+25][0][1] - align[index][0][1]\n",
    "    y_out = align[index+25][0][2] - align[index][0][2]\n",
    "    theta_out = align[index+25][0][3] - align[index][0][3]\n",
    "    \n",
    "    if (i == int(ind[ind_count]) and ind_count%2 ==0):\n",
    "        test_in3.append([del_v, del_w, dt_out])\n",
    "        test_out3.append([x_out, y_out, theta_out])\n",
    "        ind_count+=1\n",
    "    elif (i == int(ind[ind_count]) and ind_count%2 ==1):\n",
    "        val_in3.append([del_v, del_w, dt_out])\n",
    "        val_out3.append([x_out, y_out, theta_out])\n",
    "        ind_count+=1\n",
    "    else:\n",
    "        train_in3.append([del_v, del_w, dt_out])\n",
    "        train_out3.append([x_out, y_out, theta_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a9a23e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.024943360982374492\n",
      "407.7092389388463 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-45-c0d7830fb47c>:14: RuntimeWarning: covariance is not positive-semidefinite.\n",
      "  y_predict3 = np.random.multivariate_normal(mu3.reshape(len(x_test3)), sigma3)\n"
     ]
    }
   ],
   "source": [
    "x_train3 = np.array(train_in3)\n",
    "x_test3 = np.array(test_in3)\n",
    "y_train3 = np.zeros(len(x_train3))\n",
    "y_true3 = np.zeros(len(x_test3))\n",
    "\n",
    "for i in range(len(x_train3)):\n",
    "    y_train3[i] = train_out3[i][0]\n",
    "    \n",
    "for i in range(len(x_test3)):\n",
    "    y_true3[i] = test_out3[i][0]\n",
    "\n",
    "mu3, sigma3 = GP(x_train3, y_train3, x_test3, 100, .1, 1e-1, 0)\n",
    "\n",
    "y_predict3 = np.random.multivariate_normal(mu3.reshape(len(x_test3)), sigma3)\n",
    "\n",
    "print(least_squares(y_predict3, y_true3))\n",
    "\n",
    "LL = log_like(x_train3, y_train3, x_test3, 100, 0.1, 1e-1)\n",
    "print(LL[0], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a9da690d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00019504, 0.00020221, 0.00015369, 0.00021408, 0.00015954,\n",
       "       0.00021872, 0.00022923, 0.00024509, 0.00027289, 0.00024174,\n",
       "       0.00024748, 0.00024972, 0.00022852, 0.00021105, 0.00019843,\n",
       "       0.00024416, 0.00025428, 0.00024055, 0.00023751, 0.00025625,\n",
       "       0.00026794, 0.00016465, 0.00024926, 0.00020683, 0.00024916,\n",
       "       0.00020469, 0.00026053, 0.0002421 , 0.00024688, 0.00024595,\n",
       "       0.000237  , 0.00025928, 0.00022249, 0.00022772, 0.00020507,\n",
       "       0.00025141, 0.00021516, 0.00019316, 0.00022141, 0.00026343,\n",
       "       0.0002381 , 0.00026309, 0.00026853, 0.00024704, 0.00020316,\n",
       "       0.00023203, 0.00021746, 0.00023645, 0.00023703, 0.00022989,\n",
       "       0.00023544, 0.00023636, 0.00023991, 0.00024717, 0.00021471,\n",
       "       0.00018997, 0.00023766, 0.00023101, 0.000195  , 0.00021953,\n",
       "       0.00020769, 0.00022887, 0.00015403, 0.00019303, 0.00026758,\n",
       "       0.00024736, 0.00023543, 0.0002446 , 0.00022548, 0.00025047,\n",
       "       0.00024003, 0.00021806, 0.00020301, 0.00022551, 0.00022782,\n",
       "       0.00025524, 0.00025951, 0.00025011, 0.00026326, 0.00023904,\n",
       "       0.00023143, 0.0002702 , 0.00023221, 0.00017364, 0.0002383 ,\n",
       "       0.00023834, 0.0002452 , 0.00019359, 0.00023898, 0.00020999,\n",
       "       0.00024211, 0.00021827, 0.0002295 , 0.00022468, 0.0002227 ,\n",
       "       0.00026377, 0.00026957, 0.00021301, 0.00022004, 0.00024879,\n",
       "       0.00026721, 0.00027198, 0.00026753, 0.00023192, 0.00019873,\n",
       "       0.00024127, 0.00022223, 0.00020534, 0.00024491, 0.00023694,\n",
       "       0.0002312 , 0.0002356 , 0.00025119, 0.00023544, 0.00019639])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b0a0521c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.053096 ,  0.0076605,  0.0177934, -0.0006507,  0.0246081,\n",
       "       -0.0145727, -0.0001374,  0.013142 ,  0.0070618,  0.0046624])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true3[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ac5bfa6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.80450886e-05, 5.73742132e-05, 5.71763091e-05, ...,\n",
       "        5.59626408e-05, 5.62931790e-05, 5.64591805e-05],\n",
       "       [5.73742132e-05, 5.70732756e-05, 5.69285324e-05, ...,\n",
       "        5.63208275e-05, 5.64823740e-05, 5.62721644e-05],\n",
       "       [5.71763091e-05, 5.69285324e-05, 5.84074033e-05, ...,\n",
       "        5.56360485e-05, 5.60321859e-05, 5.70832761e-05],\n",
       "       ...,\n",
       "       [5.59626408e-05, 5.63208275e-05, 5.56360485e-05, ...,\n",
       "        5.67197644e-05, 5.65727489e-05, 5.62233426e-05],\n",
       "       [5.62931790e-05, 5.64823740e-05, 5.60321859e-05, ...,\n",
       "        5.65727489e-05, 5.65322364e-05, 5.63581431e-05],\n",
       "       [5.64591805e-05, 5.62721644e-05, 5.70832761e-05, ...,\n",
       "        5.62233426e-05, 5.63581431e-05, 5.67038213e-05]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "87ca563e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4980.831669568006\n",
      "RBF(length_scale=17.3) + WhiteKernel(noise_level=0.000207)\n"
     ]
    }
   ],
   "source": [
    "gpr = GaussianProcessRegressor(kernel=kernel, random_state=random_state)\n",
    "\n",
    "# Fit GPR model\n",
    "gpr.fit(x_train3, y_train3)\n",
    " \n",
    "# Predict mean\n",
    "y_hat3, y_sigma3 = gpr.predict(x_test3, return_std=True)\n",
    "\n",
    "\n",
    "#print(gpr.get_params)\n",
    "print(gpr.log_marginal_likelihood_value_)\n",
    "print(gpr.kernel_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6eac4f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-53-a5fe6468d896>:3: RuntimeWarning: covariance is not positive-semidefinite.\n",
      "  y_predict3 = np.random.multivariate_normal(mu3.reshape(len(x_test3)), sigma3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04926736744367741\n",
      "407.1246950352768 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mu3, sigma3 = GP(x_train3, y_train3, x_test3, 17, .1, 1e-1, 0)\n",
    "\n",
    "y_predict3 = np.random.multivariate_normal(mu3.reshape(len(x_test3)), sigma3)\n",
    "\n",
    "print(least_squares(y_predict3, y_true3))\n",
    "\n",
    "LL = log_like(x_train3, y_train3, x_test3, 17, 0.1, 1e-1)\n",
    "print(LL[0], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4c9d7f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdt = []\n",
    "vdt = []\n",
    "dtheta = []\n",
    "vw_dt = []\n",
    "dx = []\n",
    "dy = []\n",
    "\n",
    "for i in range(len(align)-2):\n",
    "    wdt.append(align[i][1][2]*((align[i+1][0][0] - align[i][0][0])))\n",
    "    vdt.append(align[i][1][1]*((align[i+1][0][0] - align[i][0][0])))\n",
    "    vw_dt.append([align[i][1][1]*((align[i+1][0][0] - align[i][0][0])), align[i][1][2]*((align[i+1][0][0] - align[i][0][0]))])\n",
    "    dtheta.append(align[i+1][0][3] - align[i][0][3])\n",
    "    dx.append(align[i+1][0][1] - align[i][0][1])\n",
    "    dy.append(align[i+1][0][2] - align[i][0][2])\n",
    "    \n",
    "wdt = np.array(wdt)\n",
    "vdt = np.array(vdt)\n",
    "dtheta = np.array(dtheta)\n",
    "vw_dt = np.array(vw_dt)\n",
    "dx = np.array(dx)\n",
    "dy = np.array(dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "86349cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196.7972373832224\n",
      "RBF(length_scale=0.469) + WhiteKernel(noise_level=0.0391)\n"
     ]
    }
   ],
   "source": [
    "gpr = GaussianProcessRegressor(kernel=kernel, random_state=random_state)\n",
    "\n",
    "# Fit GPR model\n",
    "gpr.fit(vw_dt[0:1000], dtheta[0:1000])\n",
    " \n",
    "# Predict mean\n",
    "y_hat_dtheta, y_sigma_dtheta = gpr.predict(vw_dt[1001:1101], return_std=True)\n",
    "\n",
    "\n",
    "#print(gpr.get_params)\n",
    "print(gpr.log_marginal_likelihood_value_)\n",
    "print(gpr.kernel_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a8ff4722",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_dtheta, sigma_dtheta = GP(vw_dt[0:1000], dtheta[0:1000], vw_dt[1001:1101], 0.5, .1, 1e-1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "65e37328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fc737e1edf0>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(wdt[0:500], dx[0:500], color = 'blue')\n",
    "plt.scatter(vdt[0:500], dx[0:500], color = 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e145ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
